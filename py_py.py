# -*- coding: utf-8 -*-
"""py.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eAAipn7zK6t-3Dayc2eidHHlFxWgUSk2
"""

pip install flask-ngrok

from google.colab import drive
drive.mount('/content/drive/')

from flask import Flask, request, render_template
from flask_ngrok import run_with_ngrok
import numpy as np
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import load_model
import pickle
import re
import string


# Load the model
model = load_model('/content/drive/MyDrive/NLP Project/sarcasm_model.h5')



# Load the tokenizer
# Note: Tokenizer should be saved after fitting on the data and loaded here. For simplicity, we reinitialize it.
max_features = 25000
tokenizer = Tokenizer(num_words=max_features, lower=True, split=' ')

# Fit the tokenizer on the training data here. This step should match the tokenizer used during training.
import pickle

with open('/content/drive/MyDrive/NLP Project/tokenizer.pickle', 'rb') as handle:
    tokenizer = pickle.load(handle)

maxlen = 240  # Use the same maxlen used during training

app = Flask(__name__)
run_with_ngrok(app)

def cleanData(text):
    text = re.sub(r'\d+', '', text)
    text = "".join([char for char in text if char not in string.punctuation])
    return text

@app.route('/')
def home():
    return render_template('index.html')

@app.route('/predict', methods=['POST'])
def predict():
    if request.method == 'POST':
        headline = request.form['headline']
        cleaned_headline = cleanData(headline)
        seq = tokenizer.texts_to_sequences([cleaned_headline])
        padded = pad_sequences(seq, maxlen=maxlen)
        pred = model.predict(padded)
        label = 'Sarcastic' if pred[0][1] > pred[0][0] else 'Not Sarcastic'
        return render_template('index.html', prediction_text=f'Prediction: {label}')

if __name__ == "__main__":
    app.run()

